<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="23" skipped="14" tests="177" time="32.699" timestamp="2025-07-14T19:25:37.186107" hostname="Stefano.local"><properties><property name="hypothesis-statistics-tests/property/test_expression_parser.py::test_expression_matches_eval" value="dGVzdHMvcHJvcGVydHkvdGVzdF9leHByZXNzaW9uX3BhcnNlci5weTo6dGVzdF9leHByZXNzaW9uX21hdGNoZXNfZXZhbDoKCiAgLSBkdXJpbmcgZ2VuZXJhdGUgcGhhc2UgKDAuMzMgc2Vjb25kcyk6CiAgICAtIFR5cGljYWwgcnVudGltZXM6IH4gMW1zLCBvZiB3aGljaCA8IDFtcyBpbiBkYXRhIGdlbmVyYXRpb24KICAgIC0gMTAwIHBhc3NpbmcgZXhhbXBsZXMsIDAgZmFpbGluZyBleGFtcGxlcywgMCBpbnZhbGlkIGV4YW1wbGVzCgogIC0gU3RvcHBlZCBiZWNhdXNlIHNldHRpbmdzLm1heF9leGFtcGxlcz0xMDA=" /><property name="hypothesis-statistics-tests/property/test_depth_and_backoff.py::test_retry_backoff_timings" value="dGVzdHMvcHJvcGVydHkvdGVzdF9kZXB0aF9hbmRfYmFja29mZi5weTo6dGVzdF9yZXRyeV9iYWNrb2ZmX3RpbWluZ3M6CgogIC0gZHVyaW5nIGdlbmVyYXRlIHBoYXNlICgxNC4zOSBzZWNvbmRzKToKICAgIC0gVHlwaWNhbCBydW50aW1lczogfiAxNDAtMTQ0IG1zLCBvZiB3aGljaCA8IDFtcyBpbiBkYXRhIGdlbmVyYXRpb24KICAgIC0gMTAwIHBhc3NpbmcgZXhhbXBsZXMsIDAgZmFpbGluZyBleGFtcGxlcywgMCBpbnZhbGlkIGV4YW1wbGVzCgogIC0gU3RvcHBlZCBiZWNhdXNlIHNldHRpbmdzLm1heF9leGFtcGxlcz0xMDA=" /><property name="hypothesis-statistics-tests/property/test_depth_and_backoff.py::test_depth_guard_abort" value="dGVzdHMvcHJvcGVydHkvdGVzdF9kZXB0aF9hbmRfYmFja29mZi5weTo6dGVzdF9kZXB0aF9ndWFyZF9hYm9ydDoKCiAgLSBkdXJpbmcgZ2VuZXJhdGUgcGhhc2UgKDQuNTIgc2Vjb25kcyk6CiAgICAtIFR5cGljYWwgcnVudGltZXM6IH4gMTQwLTE2OCBtcywgb2Ygd2hpY2ggPCAxbXMgaW4gZGF0YSBnZW5lcmF0aW9uCiAgICAtIDMwIHBhc3NpbmcgZXhhbXBsZXMsIDAgZmFpbGluZyBleGFtcGxlcywgMCBpbnZhbGlkIGV4YW1wbGVzCgogIC0gU3RvcHBlZCBiZWNhdXNlIG5vdGhpbmcgbGVmdCB0byBkbw==" /></properties><testcase classname="" name="tests.benchmark.test_scale" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/benchmark/test_scale.py', 3, 'Skipped: Load/perf benchmarks are skipped in default test run (enable via BENCHMARK env)')</skipped></testcase><testcase classname="" name="tests.observability.test_node_spans" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/observability/test_node_spans.py', 24, 'Skipped: OpenTelemetry SDK with InMemorySpanExporter unavailable')</skipped></testcase><testcase classname="" name="tests.property.test_models" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/property/test_models.py', 7, 'Skipped: Hypothesis not installed')</skipped></testcase><testcase classname="" name="tests.property.test_node_configs" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/property/test_node_configs.py', 9, 'Skipped: Hypothesis not installed')</skipped></testcase><testcase classname="" name="tests.recovery.test_resume" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/recovery/test_resume.py', 4, 'Skipped: Resume functionality not yet implemented; tracked in issue #124')</skipped></testcase><testcase classname="" name="tests.vector.test_annoy_adapter" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/vector/test_annoy_adapter.py', 7, "Skipped: could not import 'annoy': No module named 'annoy'")</skipped></testcase><testcase classname="" name="tests.vector.test_chroma_adapter" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/vector/test_chroma_adapter.py', 9, "Skipped: could not import 'chromadb': No module named 'chromadb'")</skipped></testcase><testcase classname="" name="tests.vector.test_embedding_and_hashing" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/vector/test_embedding_and_hashing.py', 7, 'Skipped: Vector embedding/hash tests removed in refactor')</skipped></testcase><testcase classname="" name="tests.vector.test_hybrid_embedder" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/vector/test_hybrid_embedder.py', 9, "Skipped: could not import 'sentence_transformers': No module named 'sentence_transformers'")</skipped></testcase><testcase classname="" name="tests.vector.test_pgvector_store" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/vector/test_pgvector_store.py', 23, "Skipped: could not import 'asyncpg': No module named 'asyncpg'")</skipped></testcase><testcase classname="" name="tests.vector.test_reranker" time="0.000"><skipped message="collection skipped">('/Users/nooz/iceOSv1(A)/tests/vector/test_reranker.py', 7, "Skipped: could not import 'sentence_transformers': No module named 'sentence_transformers'")</skipped></testcase><testcase classname="tests.context.test_async_manager" name="test_branch_isolation_concurrent_updates" time="0.150" /><testcase classname="tests.sdk.test_capability_card" name="test_custom_tool_registration_card" time="0.002" /><testcase classname="tests.sdk.test_capability_card" name="test_card_purpose_examples_mapping" time="0.001" /><testcase classname="tests.sdk.test_capability_card" name="test_from_tool_cls" time="0.000" /><testcase classname="tests.sdk.test_capability_card" name="test_ai_node_capability_card" time="0.001" /><testcase classname="tests.sdk.test_capability_card" name="test_toolservice_cards_exposes_builtins" time="0.001"><failure message="AssertionError: assert False&#10; +  where False = &lt;built-in method issubset of set object at 0x10e2ec2e0&gt;({'computer', 'http_request', 'internal_mcp', 'sleep', 'webhook_emitter'})&#10; +    where &lt;built-in method issubset of set object at 0x10e2ec2e0&gt; = {'computer', 'file_search', 'http_request', 'sleep', 'sum', 'web_search'}.issubset">tests/sdk/test_capability_card.py:29: in test_toolservice_cards_exposes_builtins
    assert expected.issubset(card_ids)
E   AssertionError: assert False
E    +  where False = &lt;built-in method issubset of set object at 0x10e2ec2e0&gt;({'computer', 'http_request', 'internal_mcp', 'sleep', 'webhook_emitter'})
E    +    where &lt;built-in method issubset of set object at 0x10e2ec2e0&gt; = {'computer', 'file_search', 'http_request', 'sleep', 'sum', 'web_search'}.issubset</failure></testcase><testcase classname="tests.sdk.test_meta_deprecation" name="test_iceos_meta_package_emits_deprecation_warning" time="0.001" /><testcase classname="tests.events.test_dispatcher" name="test_publish_subscribe_roundtrip" time="0.052" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_validate_or_raise_with_none_schema" time="0.000" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_coerce_types_success[output1-_PersonModel-expected1]" time="0.001" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_validate_or_raise_with_pydantic_model" time="0.002" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_coerce_value_basic_types" time="0.001" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_coerce_types_error_collection" time="0.000" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_validate_or_raise_with_mapping_schema" time="0.000" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_coerce_value_invalid_int" time="0.000" /><testcase classname="tests.utils.test_type_coercion_and_validation" name="test_coerce_types_success[output0-schema0-expected0]" time="0.000" /><testcase classname="tests.lint.test_no_openai_models" name="test_no_openai_models" time="0.153" /><testcase classname="tests.utils.test_token_counter" name="test_estimate_tokens" time="0.000" /><testcase classname="tests.cli.test_load_module_path" name="test_load_module_from_path" time="0.002" /><testcase classname="tests.chain.test_script_chain_limits" name="test_depth_ceiling_stops_execution" time="0.145" /><testcase classname="tests.property.test_expression_parser" name="test_expression_matches_eval" time="0.331" /><testcase classname="tests.utils.test_prompt_renderer" name="test_render_prompt_with_jinja2" time="0.001" /><testcase classname="tests.utils.test_prompt_renderer" name="test_render_prompt_str_format_fallback" time="0.001" /><testcase classname="tests.orchestrator.test_runtime_validate" name="test_runtime_validate_failure" time="0.143" /><testcase classname="tests.property.test_depth_and_backoff" name="test_retry_backoff_timings" time="14.391" /><testcase classname="tests.property.test_depth_and_backoff" name="test_depth_guard_abort" time="4.524" /><testcase classname="tests.frosty.test_integration" name="test_memory_context_retrieval" time="0.001"><failure message="assert 0 &gt; 0&#10; +  where 0 = len([])">tests/frosty/test_integration.py:140: in test_memory_context_retrieval
    assert len(context_items) &gt; 0
E   assert 0 &gt; 0
E    +  where 0 = len([])</failure></testcase><testcase classname="tests.frosty.test_integration" name="test_scriptchain_building" time="0.001"><failure message="AttributeError: 'FrostyContext' object has no attribute 'get_ice_context_manager'">tests/frosty/test_integration.py:227: in test_scriptchain_building
    ice_context_manager = context.get_ice_context_manager()
E   AttributeError: 'FrostyContext' object has no attribute 'get_ice_context_manager'</failure></testcase><testcase classname="tests.frosty.test_integration" name="test_full_ai_flow" time="0.001" /><testcase classname="tests.frosty.test_integration" name="test_guardrails_enforcement" time="0.001" /><testcase classname="tests.frosty.test_integration" name="test_sub_context_creation" time="0.001"><failure message="AttributeError: 'FrostyContext' object has no attribute 'get_sub_context'. Did you mean: 'create_sub_context'?">tests/frosty/test_integration.py:205: in test_sub_context_creation
    retrieved_context = await context.get_sub_context("web_development")
E   AttributeError: 'FrostyContext' object has no attribute 'get_sub_context'. Did you mean: 'create_sub_context'?</failure></testcase><testcase classname="tests.frosty.test_integration" name="test_cli_integration" time="0.001" /><testcase classname="tests.frosty.test_integration" name="test_event_emission" time="0.001" /><testcase classname="tests.frosty.test_integration" name="test_multi_agent_collaboration" time="0.001" /><testcase classname="tests.frosty.test_integration" name="test_domain_agent_creation" time="0.001"><failure message="NameError: name 'capabilities' is not defined">tests/frosty/test_integration.py:169: in test_domain_agent_creation
    web_agent = await context.build_agent_for_domain(
src/frosty/context.py:147: in build_agent_for_domain
    class _DomainAgent(BaseAgent):  # type: ignore[misc]
src/frosty/context.py:149: in _DomainAgent
    capabilities = capabilities or []
E   NameError: name 'capabilities' is not defined</failure></testcase><testcase classname="tests.lint.test_no_dynamic_imports" name="test_no_importlib_import_module_usage_outside_allowed" time="0.113" /><testcase classname="tests.frosty.test_basic_structure" name="test_context_validation" time="0.001" /><testcase classname="tests.frosty.test_basic_structure" name="test_agent_not_found" time="0.003" /><testcase classname="tests.frosty.test_basic_structure" name="test_agent_registration" time="0.001" /><testcase classname="tests.frosty.test_basic_structure" name="test_flow_design_agent_run" time="0.004" /><testcase classname="tests.frosty.test_basic_structure" name="test_memory_operations" time="0.001" /><testcase classname="tests.frosty.test_basic_structure" name="test_flow_design_agent_creation" time="0.001" /><testcase classname="tests.frosty.test_basic_structure" name="test_frosty_context_initialization" time="0.001"><failure message="assert None is not None&#10; +  where None = &lt;src.frosty.context.FrostyContext object at 0x10e903e80&gt;.planner">tests/frosty/test_basic_structure.py:16: in test_frosty_context_initialization
    assert context.planner is not None
E   assert None is not None
E    +  where None = &lt;src.frosty.context.FrostyContext object at 0x10e903e80&gt;.planner</failure></testcase><testcase classname="tests.frosty.test_basic_structure" name="test_agent_validation" time="0.001" /><testcase classname="tests.frosty.test_basic_structure" name="test_guardrails_validation" time="0.001" /><testcase classname="tests.utils.test_perf" name="test_weighted_semaphore_invalid_weight[0]" time="0.000" /><testcase classname="tests.utils.test_perf" name="test_weighted_semaphore_acquires_and_releases" time="0.001" /><testcase classname="tests.utils.test_perf" name="test_estimate_complexity_ai_vs_tool" time="0.000" /><testcase classname="tests.utils.test_perf" name="test_weighted_semaphore_invalid_weight[-1]" time="0.000" /><testcase classname="tests.nodes.test_node_registry" name="test_builtin_executors_registered" time="0.000" /><testcase classname="tests.security.test_data_flows" name="test_sensitive_data_flow_allowed_after_anonymizer" time="0.000" /><testcase classname="tests.security.test_data_flows" name="test_sensitive_data_flow_blocked" time="0.000" /><testcase classname="tests.integration.test_loop_node_integration" name="test_loop_node_via_script_chain" time="0.005"><failure message="AttributeError: 'LoopNodeConfig' object has no attribute 'level'">tests/integration/test_loop_node_integration.py:27: in test_loop_node_via_script_chain
    chain = ScriptChain(nodes=[node_cfg], name="loop-integration")
src/ice_orchestrator/script_chain.py:149: in __init__
    self.graph = DependencyGraph(nodes)
src/ice_orchestrator/graph/dependency_graph.py:18: in __init__
    self._assign_levels(nodes)
src/ice_orchestrator/graph/dependency_graph.py:49: in _assign_levels
    node.level = (
E   AttributeError: 'LoopNodeConfig' object has no attribute 'level'</failure></testcase><testcase classname="tests.chain_builder.test_builder_engine" name="test_builder_engine_render_valid_python" time="0.003" /><testcase classname="tests.orchestrator.test_dependency_graph" name="test_level_assignment" time="0.001" /><testcase classname="tests.orchestrator.test_dependency_graph" name="test_cycle_detection" time="0.001" /><testcase classname="tests.api.test_builder_resume" name="test_builder_export_resume_roundtrip" time="0.009" /><testcase classname="tests.orchestrator.test_transactions" name="test_transaction_commit" time="0.001"><failure message="TypeError: Transaction.__init__() got an unexpected keyword argument 'store'">tests/orchestrator/test_transactions.py:18: in test_transaction_commit
    tx = Transaction(store=tmp_store, scope="test_chain")
E   TypeError: Transaction.__init__() got an unexpected keyword argument 'store'</failure></testcase><testcase classname="tests.orchestrator.test_transactions" name="test_transaction_rollback" time="0.001"><failure message="TypeError: Transaction.__init__() got an unexpected keyword argument 'store'">tests/orchestrator/test_transactions.py:29: in test_transaction_rollback
    tx = Transaction(store=tmp_store, scope="test_chain")
E   TypeError: Transaction.__init__() got an unexpected keyword argument 'store'</failure></testcase><testcase classname="tests.contracts.test_web_search_tool" name="test_web_search_tool_mocked_serpapi" time="0.066" /><testcase classname="tests.providers.test_costs" name="test_calculate_cost_unknown_model_returns_zero" time="0.001" /><testcase classname="tests.providers.test_costs" name="test_calculate_cost_openai_gpt4o" time="0.000" /><testcase classname="tests.utils.test_public_decorator" name="test_public_decorator_idempotent" time="0.000" /><testcase classname="tests.utils.test_public_decorator" name="test_public_decorator_adds_symbol_to___all__" time="0.000" /><testcase classname="tests.utils.test_public_decorator" name="test_public_decorator_respects_custom_export_name" time="0.000" /><testcase classname="tests.providers.test_cost_calc_extra" name="test_calculate_cost_zero_usage" time="0.000" /><testcase classname="tests.api.test_mcp_endpoints" name="test_mcp_roundtrip" time="0.010" /><testcase classname="tests.chain.test_script_chain" name="test_script_chain_ai_and_tool" time="0.009" /><testcase classname="tests.lint.test_no_unresolved_placeholders" name="test_prompt_placeholder_validation" time="0.007" /><testcase classname="tests.context.test_memory_di" name="test_null_memory_usage" time="0.139" /><testcase classname="tests.agents.test_router_agent" name="test_router_agent_forwards" time="0.139" /><testcase classname="tests.nodes.test_loop_node" name="test_loop_node_static_items" time="0.001"><failure message="TypeError: loop_executor received incompatible cfg type">tests/nodes/test_loop_node.py:17: in test_loop_node_static_items
    result = await loop_executor(_DummyChain(), cfg, ctx={})  # type: ignore[arg-type]
src/ice_sdk/executors/loop.py:59: in loop_executor
    raise TypeError("loop_executor received incompatible cfg type")
E   TypeError: loop_executor received incompatible cfg type</failure></testcase><testcase classname="tests.nodes.test_loop_node" name="test_loop_node_ctx_items" time="0.001"><failure message="TypeError: loop_executor received incompatible cfg type">tests/nodes/test_loop_node.py:28: in test_loop_node_ctx_items
    result = await loop_executor(_DummyChain(), cfg, ctx)  # type: ignore[arg-type]
src/ice_sdk/executors/loop.py:59: in loop_executor
    raise TypeError("loop_executor received incompatible cfg type")
E   TypeError: loop_executor received incompatible cfg type</failure></testcase><testcase classname="tests.cli.functional.test_chain_run" name="test_chain_run" time="0.007"><failure message="assert 2 == 0&#10; +  where 2 = &lt;Result SystemExit(2)&gt;.exit_code">tests/cli/functional/test_chain_run.py:32: in test_chain_run
    assert result.exit_code == 0
E   assert 2 == 0
E    +  where 2 = &lt;Result SystemExit(2)&gt;.exit_code</failure></testcase><testcase classname="tests.utils.test_logging" name="test_setup_logger_idempotent" time="0.000" /><testcase classname="tests.executors.test_tool_input_mapping" name="test_tool_args_placeholder_substitution" time="0.014" /><testcase classname="tests.chain.test_retry_logic" name="test_retry_succeeds_on_second_attempt" time="0.007" /><testcase classname="tests.context.test_memory" name="test_similarity_search_basic" time="0.001" /><testcase classname="tests.config.test_runtime_config.TestRuntimeConfig" name="test_default_values" time="0.000" /><testcase classname="tests.config.test_runtime_config.TestRuntimeConfig" name="test_from_env_with_values" time="0.000" /><testcase classname="tests.config.test_runtime_config.TestRuntimeConfig" name="test_budget_fail_open_parsing" time="0.001" /><testcase classname="tests.config.test_runtime_config.TestRuntimeConfig" name="test_global_runtime_config_reload" time="0.002" /><testcase classname="tests.config.test_runtime_config.TestRuntimeConfig" name="test_from_env_without_values" time="0.000" /><testcase classname="tests.chain_builder.test_builder_advanced" name="test_advanced_settings_render" time="0.002" /><testcase classname="tests.orchestrator.test_production_readiness" name="test_circular_dependency_raises" time="0.001" /><testcase classname="tests.orchestrator.test_production_readiness" name="test_airgap_enforcement_blocks_external_io" time="0.001" /><testcase classname="tests.orchestrator.test_production_readiness" name="test_persistence_batches_until_threshold" time="0.001" /><testcase classname="tests.cli.test_plugin_hello" name="test_cli_hello_ping" time="0.001"><failure message="TypeError: CliRunner.__init__() got an unexpected keyword argument 'mix_stderr'">tests/cli/test_plugin_hello.py:38: in test_cli_hello_ping
    runner = CliRunner(mix_stderr=False)
E   TypeError: CliRunner.__init__() got an unexpected keyword argument 'mix_stderr'</failure></testcase><testcase classname="tests.cli.test_plugin_hello" name="test_discover_plugins_includes_hello" time="0.001"><failure message="AssertionError: hello plugin not discovered&#10;assert 'hello' in set()">tests/cli/test_plugin_hello.py:34: in test_discover_plugins_includes_hello
    assert "hello" in module_names, "hello plugin not discovered"
E   AssertionError: hello plugin not discovered
E   assert 'hello' in set()</failure></testcase><testcase classname="tests.agents.test_flow_designer" name="test_design_session" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[NodeExecutionResult]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[NodeMetadata]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[IceCopilot]" time="0.000"><failure message="AssertionError: IceCopilot missing from __all__&#10;assert 'IceCopilot' in ['BaseNode', 'BaseTool', 'ToolService', 'NodeConfig', 'NodeExecutionResult', 'NodeMetadata', ...]&#10; +  where ['BaseNode', 'BaseTool', 'ToolService', 'NodeConfig', 'NodeExecutionResult', 'NodeMetadata', ...] = &lt;module 'ice_sdk' from '/Users/nooz/iceOSv1(A)/src/ice_sdk/__init__.py'&gt;.__all__">tests/sdk/test_public_api.py:38: in test_symbol_exists
    assert symbol in sdk.__all__, f"{symbol} missing from __all__"
E   AssertionError: IceCopilot missing from __all__
E   assert 'IceCopilot' in ['BaseNode', 'BaseTool', 'ToolService', 'NodeConfig', 'NodeExecutionResult', 'NodeMetadata', ...]
E    +  where ['BaseNode', 'BaseTool', 'ToolService', 'NodeConfig', 'NodeExecutionResult', 'NodeMetadata', ...] = &lt;module 'ice_sdk' from '/Users/nooz/iceOSv1(A)/src/ice_sdk/__init__.py'&gt;.__all__</failure></testcase><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[BaseTool]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[extensions]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[BaseNode]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[MessageTemplate]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[ServiceLocator]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[NodeConfig]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[ToolService]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_no_unexpected_exports" time="0.001"><failure message="AssertionError: __all__ diverged from contract&#10;assert {'BaseNode', ...eConfig', ...} == {'BaseNode', ...emplate', ...}&#10;  Extra items in the right set:&#10;  'IceCopilot'&#10;  Use -v to get more diff">tests/sdk/test_public_api.py:44: in test_no_unexpected_exports
    assert set(sdk.__all__) == PUBLIC_API, "__all__ diverged from contract"
E   AssertionError: __all__ diverged from contract
E   assert {'BaseNode', ...eConfig', ...} == {'BaseNode', ...emplate', ...}
E     Extra items in the right set:
E     'IceCopilot'
E     Use -v to get more diff</failure></testcase><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[LLMConfig]" time="0.000" /><testcase classname="tests.sdk.test_public_api" name="test_symbol_exists[GraphContextManager]" time="0.000" /><testcase classname="tests.contracts.test_schema_drift" name="test_schema_drift_detection" time="0.001"><failure message="Failed: DID NOT RAISE &lt;class 'Exception'&gt;">tests/contracts/test_schema_drift.py:30: in test_schema_drift_detection
    with pytest.raises(Exception):
E   Failed: DID NOT RAISE &lt;class 'Exception'&gt;</failure></testcase><testcase classname="tests.orchestrator.test_script_chain_circular_dependency" name="test_circular_dependency_detection" time="0.005" /><testcase classname="tests.nodes.test_evaluator_node" name="test_evaluator_node_passes" time="0.001" /><testcase classname="tests.nodes.test_evaluator_node" name="test_evaluator_node_fails" time="0.001" /><testcase classname="tests.sdk.test_removed_shims" name="test_shim_removed[ice_agents]" time="0.001" /><testcase classname="tests.sdk.test_removed_shims" name="test_shim_removed[ice_sdk.tools.webhook]" time="0.000" /><testcase classname="tests.sdk.test_removed_shims" name="test_shim_removed[ice_sdk.tools.hosted]" time="0.000" /><testcase classname="tests.sdk.test_removed_shims" name="test_shim_removed[ice_sdk.tools.mcp_tool]" time="0.000" /><testcase classname="tests.contracts.test_http_request_tool" name="test_http_request_tool_against_local_server" time="0.011" /><testcase classname="tests.executors.test_condition_executor" name="test_condition_false" time="0.001" /><testcase classname="tests.executors.test_condition_executor" name="test_condition_true" time="0.001" /><testcase classname="tests.executors.test_condition_executor" name="test_condition_error" time="0.001" /><testcase classname="tests.agents.test_frosty_alias" name="test_frosty_context_initialization" time="0.000" /><testcase classname="tests.agents.test_frosty_alias" name="test_node_builder_agent_import" time="0.000" /><testcase classname="tests.agents.test_frosty_alias" name="test_flow_design_agent_import" time="0.000" /><testcase classname="tests.agents.test_frosty_alias" name="test_direct_imports_work" time="0.000" /><testcase classname="tests.orchestrator.test_deprecated_imports" name="test_deprecated_base_script_chain_import" time="0.000" /><testcase classname="tests.orchestrator.test_script_chain_patches" name="test_execute_level_handles_exceptions" time="0.008" /><testcase classname="tests.orchestrator.test_script_chain_patches" name="test_resolve_nested_path_root" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_get_status" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_tool_execution_tracking" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_fail_open_behavior" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_llm_call_tracking" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_custom_limits" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_basic_initialization" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_cost_budget_enforcement" time="0.001" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_environment_variable_limits" time="0.000" /><testcase classname="tests.providers.test_budget_enforcer.TestBudgetEnforcer" name="test_fail_closed_behavior" time="0.000" /><testcase classname="tests.contracts.test_layers" name="test_import_contracts_pass" time="0.328" /><testcase classname="tests.api.test_rate_limit" name="test_rate_limit_exceeded" time="0.003"><failure message="assert 200 == 429&#10; +  where 200 = &lt;Response [200 OK]&gt;.status_code">tests/api/test_rate_limit.py:23: in test_rate_limit_exceeded
    assert resp.status_code == 429
E   assert 200 == 429
E    +  where 200 = &lt;Response [200 OK]&gt;.status_code</failure></testcase><testcase classname="tests.nodes.test_echo_node" name="test_echo_node_validation_error" time="0.001" /><testcase classname="tests.nodes.test_echo_node" name="test_echo_node_happy_path" time="0.001" /><testcase classname="tests.test_legacy_and_guardrails" name="test_import_guardrails_module" time="0.001" /><testcase classname="tests.test_legacy_and_guardrails" name="test_import_legacy_nodes_module" time="0.001" /><testcase classname="tests.cli.test_chain_run_cli_command" name="test_cli_chain_run_json" time="0.000"><skipped type="pytest.skip" message="CLI run JSON output format pending refactor">/Users/nooz/iceOSv1(A)/tests/cli/test_chain_run_cli_command.py:54: CLI run JSON output format pending refactor</skipped></testcase><testcase classname="tests.integration.test_llm_prompt_usage" name="test_prompt_usage_accounting" time="0.001" /><testcase classname="tests.integration.test_llm_prompt_usage" name="test_timeout_path" time="0.002" /><testcase classname="tests.lint.test_no_duplicate_frosty_paths" name="test_no_duplicate_frosty_paths" time="6.238" /><testcase classname="tests.chain.test_cache_toggle" name="test_chain_level_cache_disabled" time="0.293" /><testcase classname="tests.chain.test_cache_toggle" name="test_node_level_cache_disabled" time="0.287" /><testcase classname="tests.api.test_fastapi_smoke.TestFastAPISmoke" name="test_tools_endpoint" time="0.283" /><testcase classname="tests.api.test_fastapi_smoke.TestFastAPISmoke" name="test_health_endpoint" time="0.001" /><testcase classname="tests.api.test_fastapi_smoke.TestFastAPISmoke" name="test_not_found" time="0.002" /><testcase classname="tests.context.test_formatter_and_manager" name="test_context_formatter_truncates_long_text" time="0.001" /><testcase classname="tests.context.test_formatter_and_manager" name="test_graph_context_manager_update_and_get" time="0.139" /><testcase classname="tests.nodes.test_tool_node_sum" name="test_tool_node_sum_execution" time="0.166" /><testcase classname="tests.integration.test_branching_chain" name="test_condition_branch_execution" time="0.007"><failure message="assert False is True&#10; +  where False = ChainExecutionResult(success=False, error=&quot;Node cond failed: Condition evaluation failed: name 'branch' is not defined..., chain_metadata=None, execution_time=0.002238, token_stats={'total_tokens': 0, 'total_cost': 0.0, 'node_metrics': {}}).success">tests/integration/test_branching_chain.py:49: in test_condition_branch_execution
    assert result.success is True
E   assert False is True
E    +  where False = ChainExecutionResult(success=False, error="Node cond failed: Condition evaluation failed: name 'branch' is not defined..., chain_metadata=None, execution_time=0.002238, token_stats={'total_tokens': 0, 'total_cost': 0.0, 'node_metrics': {}}).success</failure></testcase><testcase classname="tests.api.test_cost_tracing" name="test_cost_entry_recorded" time="0.002"><failure message="ModuleNotFoundError: No module named 'asyncpg'">tests/api/test_cost_tracing.py:22: in test_cost_entry_recorded
    async with get_session_cm() as session:
../.pyenv/versions/3.10.11/lib/python3.10/contextlib.py:199: in __aenter__
    return await anext(self.gen)
services/db.py:132: in session_cm
    session = await gen.__anext__()
services/db.py:105: in get_session
    session: AsyncSession = _get_session_factory()()  # type: ignore[call-arg]
services/db.py:92: in _get_session_factory
    _SessionFactory = async_sessionmaker(bind=_get_engine(), expire_on_commit=False)
services/db.py:71: in _get_engine
    _engine = create_async_engine(db_url, **kwargs)  # type: ignore[arg-type]
.venv/lib/python3.10/site-packages/sqlalchemy/ext/asyncio/engine.py:120: in create_async_engine
    sync_engine = _create_engine(url, **kw)
&lt;string&gt;:2: in create_engine
    ???
.venv/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py:281: in warned
    return fn(*args, **kwargs)  # type: ignore[no-any-return]
.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py:602: in create_engine
    dbapi = dbapi_meth(**dbapi_args)
.venv/lib/python3.10/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1100: in import_dbapi
    return AsyncAdapt_asyncpg_dbapi(__import__("asyncpg"))
E   ModuleNotFoundError: No module named 'asyncpg'</failure></testcase><testcase classname="tests.orchestrator.test_network_factory" name="test_network_factory_from_yaml" time="0.011" /><testcase classname="tests.cli.test_cli_error_paths" name="test_help_exit_code_zero" time="0.000"><skipped type="pytest.skip" message="CLI patch not working - skip for now">/Users/nooz/iceOSv1(A)/tests/cli/test_cli_error_paths.py:12: CLI patch not working - skip for now</skipped></testcase><testcase classname="tests.cli.test_cli_error_paths" name="test_unknown_command_exit_code_two" time="0.004" /><testcase classname="tests.cli.test_cli_error_paths" name="test_tool_ls_json_valid_json" time="0.000"><skipped type="pytest.skip" message="Legacy 'ice tool' commands removed - use 'ice create tool' instead">/Users/nooz/iceOSv1(A)/tests/cli/test_cli_error_paths.py:28: Legacy 'ice tool' commands removed - use 'ice create tool' instead</skipped></testcase><testcase classname="tests.context.test_context_truncation" name="test_update_node_context_truncates_long_payload" time="0.140" /><testcase classname="tests.context.test_scoped_context_store" name="test_scoped_context_store_isolation" time="0.001" /><testcase classname="tests.chain.test_caching" name="test_lru_cache_skips_second_execution" time="0.289" /><testcase classname="tests.integration.test_llm_service_integration" name="test_llm_service_generate_round_trip" time="0.001" /><testcase classname="tests.context.test_context_eviction_and_isolation" name="test_lru_eviction_of_old_sessions" time="0.139" /><testcase classname="tests.context.test_context_eviction_and_isolation" name="test_concurrent_contexts_isolation" time="0.137" /><testcase classname="tests.api.test_deploy" name="test_deploy_and_invoke_chain" time="0.003"><failure message="assert 400 == 200&#10; +  where 400 = &lt;Response [400 Bad Request]&gt;.status_code">tests/api/test_deploy.py:48: in test_deploy_and_invoke_chain
    assert resp.status_code == 200
E   assert 400 == 200
E    +  where 400 = &lt;Response [400 Bad Request]&gt;.status_code</failure></testcase><testcase classname="tests.api.test_deploy" name="test_deployment_health_endpoints" time="0.002"><failure message="AssertionError: assert 'Deployment not found' in 'Not Found'">tests/api/test_deploy.py:129: in test_deployment_health_endpoints
    assert "Deployment not found" in resp.json()["detail"]
E   AssertionError: assert 'Deployment not found' in 'Not Found'</failure></testcase><testcase classname="tests.api.test_deploy" name="test_deployment_error_handling" time="0.001"><failure message="AssertionError: assert 'draft_id not found' in 'Not Found'">tests/api/test_deploy.py:108: in test_deployment_error_handling
    assert "draft_id not found" in resp.json()["detail"]
E   AssertionError: assert 'draft_id not found' in 'Not Found'</failure></testcase><testcase classname="tests.api.test_builder_service" name="test_builder_happy_path" time="0.005" /><testcase classname="tests.executors.test_agent_allowed_tools" name="test_allowed_tools_whitelist" time="0.426" /></testsuite></testsuites>