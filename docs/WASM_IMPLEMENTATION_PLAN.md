# WASM Implementation Plan for iceOS

## âœ… **STATUS: COMPLETED** (January 2025)

**ðŸŽ‰ Successfully implemented WASM sandboxing for ALL node types with:**
- Universal WASM executor using `wasmtime-py`
- Resource monitoring and limits (CPU, memory, timeout)
- Security audit test suite (12+ comprehensive tests)
- OpenTelemetry integration for observability
- Production-ready with proper error handling

## Overview

Implement WebAssembly sandboxing for ALL node types, starting with backend WASM now and evolving to frontend WASM when Canvas is ready.

## Why ALL Nodes Need WASM Sandboxing

Every node executor runs Python code and poses security risks:

```python
# âœ… NOW SECURED WITH WASM:
@register_node("tool")      # Executes tool Python implementations  
@register_node("agent")     # Executes agent reasoning logic
@register_node("code")      # Executes arbitrary user code
@register_node("condition") # Evaluates Python expressions (eval!)
@register_node("loop")      # Executes iteration control logic
@register_node("workflow")  # Contains all above node types
@register_node("llm")       # Python HTTP client code
```

## âœ… Phase 1: Backend WASM (COMPLETED - January 2025)

### Architecture: Universal WASM Executor

```python
# New sandboxing layer for ALL nodes
class WasmExecutor:
    """Universal WASM runtime for secure node execution."""
    
    def __init__(self):
        # Use wasmtime-py for server-side WASM
        from wasmtime import Store, Module, Instance, Engine
        self.engine = Engine()
        
    async def execute_python_code(
        self, 
        code: str, 
        context: Dict[str, Any],
        allowed_imports: List[str] = None,
        memory_limit: int = 64_MB,
        cpu_limit: float = 5.0  # seconds
    ) -> Dict[str, Any]:
        """Execute Python code in WASM sandbox."""
        
        # Compile Python to WASM using Pyodide runtime
        wasm_module = await self._compile_python_to_wasm(code, allowed_imports)
        
        # Create isolated WASM instance
        store = Store(self.engine)
        instance = Instance(store, wasm_module, [])
        
        # Set resource limits
        store.set_fuel(cpu_limit * 1000000)  # CPU cycles
        store.set_memory_limit(memory_limit)
        
        # Execute with timeout
        try:
            result = await asyncio.wait_for(
                instance.exports.execute(context),
                timeout=cpu_limit
            )
            return {"success": True, "output": result}
        except asyncio.TimeoutError:
            return {"success": False, "error": "CPU limit exceeded"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _compile_python_to_wasm(self, code: str, imports: List[str]) -> Module:
        """Compile Python code to WASM using Pyodide."""
        # Implementation details...
        pass
```

### Updated Node Executors

```python
# Inject WASM executor into ALL node types
wasm_executor = WasmExecutor()

@register_node("tool")
async def tool_executor_wasm(workflow: Workflow, cfg: ToolNodeConfig, ctx: Dict[str, Any]):
    """WASM-sandboxed tool execution."""
    
    # Get tool code (this is the Python implementation)
    tool = registry.get_instance(NodeType.TOOL, cfg.tool_name)
    tool_code = inspect.getsource(tool.execute)
    
    # Execute tool logic in WASM sandbox
    result = await wasm_executor.execute_python_code(
        code=tool_code,
        context={"inputs": ctx, "tool_args": cfg.tool_args},
        allowed_imports=["json", "datetime", "math"],  # Tool-specific
        memory_limit=64_MB,
        cpu_limit=5.0
    )
    
    return NodeExecutionResult(
        success=result["success"],
        output=result.get("output", {}),
        error=result.get("error")
    )

@register_node("agent")  
async def agent_executor_wasm(workflow: Workflow, cfg: AgentNodeConfig, ctx: Dict[str, Any]):
    """WASM-sandboxed agent execution."""
    
    agent = registry.get_instance(NodeType.AGENT, cfg.package)
    agent_code = inspect.getsource(agent.execute)
    
    result = await wasm_executor.execute_python_code(
        code=agent_code,
        context=ctx,
        allowed_imports=["json", "datetime", "requests"],  # Agent-specific
        memory_limit=128_MB,  # Agents need more memory
        cpu_limit=30.0        # Agents can run longer
    )
    
    return NodeExecutionResult(
        success=result["success"],
        output=result.get("output", {}),
        error=result.get("error")
    )

@register_node("code")
async def code_executor_wasm(workflow: Workflow, cfg: CodeNodeConfig, ctx: Dict[str, Any]):
    """WASM-sandboxed arbitrary code execution."""
    
    result = await wasm_executor.execute_python_code(
        code=cfg.code,
        context=ctx,
        allowed_imports=cfg.imports,
        memory_limit=32_MB,   # User code gets less memory
        cpu_limit=10.0        # Shorter timeout for user code
    )
    
    return NodeExecutionResult(
        success=result["success"],
        output=result.get("output", {}),
        error=result.get("error")
    )

# Apply WASM to ALL other node types...
```

### Implementation Steps

1. **Week 1**: 
   - Install `wasmtime-py` dependency
   - Create `WasmExecutor` class
   - Update `code_executor` to use WASM
   - Basic Pythonâ†’WASM compilation

2. **Week 2**:
   - Update ALL node executors to use WASM
   - Resource limits and monitoring
   - Error handling and timeout logic
   - Integration testing

### Benefits of Starting Now

âœ… **Immediate Security**: All nodes properly sandboxed
âœ… **No Frontend Dependency**: Can implement today
âœ… **Foundation for Canvas**: Backend ready when frontend arrives
âœ… **Production Ready**: Wasmtime is battle-tested (used by Shopify, Fastly)

## Phase 2: Frontend WASM Migration (Q1 2025)

When Canvas UI is ready, migrate to browser-based execution:

### Architecture: Hybrid Execution

```typescript
// Frontend Canvas with WASM execution
class CanvasNodeExecutor {
    private pyodide: PyodideInterface;
    
    async executeNode(nodeConfig: NodeConfig, context: any): Promise<NodeResult> {
        // Execute directly in browser using Pyodide
        const result = await this.pyodide.runPython(`
            # Node execution code here
            import json
            context = ${JSON.stringify(context)}
            
            # Execute node-specific logic
            ${nodeConfig.code}
            
            # Return result
            json.dumps(output)
        `);
        
        return JSON.parse(result);
    }
}
```

### Migration Strategy

```python
# Execution location configuration
class ExecutionConfig:
    BACKEND_WASM = "backend"     # Phase 1: Server-side WASM
    FRONTEND_WASM = "frontend"   # Phase 2: Browser-side WASM
    HYBRID = "hybrid"            # Phase 3: Smart routing

# Smart execution routing
async def execute_node(config: NodeConfig, context: Dict) -> NodeResult:
    if config.execution_mode == "frontend" and canvas_available():
        # Execute in browser for instant feedback
        return await frontend_wasm_executor.execute(config, context)
    else:
        # Fallback to secure backend execution
        return await backend_wasm_executor.execute(config, context)
```

### Frontend Benefits

ðŸš€ **Instant Feedback**: Nodes execute as user builds workflow
âš¡ **Zero Latency**: No server round-trips during design
ðŸ”§ **Live Preview**: See workflow behavior in real-time
ðŸ’° **Cost Savings**: User's device provides compute power

## Phase 3: Hybrid Smart Execution (Q2 2025)

Ultimate architecture with intelligent execution routing:

### Execution Decision Matrix

| Node Type | Design Time | Production | Reason |
|-----------|-------------|------------|---------|
| **Code Node** | Frontend WASM | Backend WASM | Instant feedback vs security |
| **Tool Node** | Frontend WASM | Backend WASM | Live preview vs resource access |
| **Agent Node** | Backend WASM | Backend WASM | Always needs server resources |
| **LLM Node** | Mock/Frontend | Backend WASM | API keys stay server-side |

### Smart Routing Logic

```python
def determine_execution_location(node: NodeConfig, context: ExecutionContext) -> str:
    """Intelligently route execution based on node type and context."""
    
    if context.is_design_time and context.canvas_available:
        # Design time: prioritize speed and feedback
        if node.type in ["code", "tool"] and node.is_safe_for_frontend():
            return "frontend"
    
    if context.is_production:
        # Production: prioritize security and resource access
        return "backend"
    
    if node.requires_server_resources():
        # Agent memory, API keys, etc.
        return "backend"
    
    return "backend"  # Default to secure execution
```

## Implementation Timeline

### Immediate (Next Sprint)
- [ ] Install wasmtime-py dependency
- [ ] Create WasmExecutor prototype
- [ ] Update code_executor to use WASM
- [ ] Basic resource limits and error handling

### Month 1
- [ ] Apply WASM to ALL node executors
- [ ] Comprehensive testing and security audit  
- [ ] Performance benchmarking vs current approach
- [ ] Documentation and developer guides

### Q1 2025 (When Canvas Ready)
- [ ] Pyodide integration in frontend
- [ ] Hybrid execution routing logic
- [ ] Real-time node execution in Canvas
- [ ] Performance optimization and caching

### Q2 2025 (Advanced Features)
- [ ] Multi-language WASM (JS, Rust, Go)
- [ ] Edge deployment to Cloudflare Workers
- [ ] Advanced resource monitoring
- [ ] Smart execution cost optimization

## Technical Considerations

### Language Support Priority

1. **Python** (Phase 1): Pyodide for frontend, wasmtime-py for backend
2. **JavaScript** (Phase 2): Native WASM support
3. **Rust** (Phase 3): wasm-pack toolchain
4. **Go** (Phase 3): TinyGo WASM support

### Resource Management

```python
# Resource limits by node type
RESOURCE_LIMITS = {
    "code": {"memory": 32_MB, "cpu": 10_seconds},
    "tool": {"memory": 64_MB, "cpu": 5_seconds}, 
    "agent": {"memory": 128_MB, "cpu": 30_seconds},
    "llm": {"memory": 16_MB, "cpu": 2_seconds},
    "condition": {"memory": 8_MB, "cpu": 1_second},
    "loop": {"memory": 64_MB, "cpu": 60_seconds}
}
```

### Security Considerations

- **Memory Isolation**: Each node gets private memory space
- **CPU Limits**: Prevent infinite loops and DoS attacks
- **Network Isolation**: No uncontrolled external network access
- **File System**: Read-only access to approved paths only
- **Import Restrictions**: Whitelist-based module imports

## Best Practices

### Start Simple, Evolve Quickly

1. **Week 1**: Get basic WASM working for CodeNode
2. **Week 2**: Apply to all node types  
3. **Month 1**: Production ready with monitoring
4. **Q1 2025**: Frontend integration when Canvas is ready

### Design for Evolution

- **Modular Architecture**: Easy to swap execution backends
- **Configuration-Driven**: Execution location via config
- **Progressive Enhancement**: Backendâ†’Frontend migration path
- **Performance Monitoring**: Data-driven optimization decisions

### Security First

- **Assume Malicious Code**: Every node could be an attack
- **Defense in Depth**: Multiple isolation layers
- **Audit Everything**: Log all execution with resource usage
- **Fail Securely**: Timeout/limit violations kill execution

## Conclusion

**Start implementing WASM now** - don't wait for the frontend. The backend WASM foundation:

1. **Provides immediate security** for all node types
2. **Doesn't block frontend development** - can run in parallel  
3. **Creates smooth migration path** to frontend WASM
4. **Follows best practices** of progressive enhancement

The hybrid architecture gives us the best of both worlds: secure server-side execution for production and instant client-side execution for design-time feedback.