# ice_api ‚Äì Spatial Computing API Gateway

## Purpose
`ice_api` exposes iceOS spatial computing functionality over HTTP + WebSocket.
It validates requests, translates them into **Workflow** executions with full spatial intelligence, and streams results back to clients with real-time canvas updates.

**üéØ Spatial Computing Features**
* **Graph Intelligence Endpoints** ‚Äì NetworkX-powered analysis, optimization suggestions, and layout hints
* **Real-time Collaboration** ‚Äì WebSocket streaming for canvas updates and cursor tracking  
* **Frosty Integration** ‚Äì AI-powered contextual suggestions and workflow optimization
* **Blueprint Management** ‚Äì Incremental construction with spatial metadata

Routes live under `ice_api.api.*` and are versioned (`/v1/...`).

## Quick-start (dev server)
```bash
uvicorn ice_api.main:app --reload
```

### Direct Execution Endpoints (NEW)
For quick testing and experimentation, use these direct execution endpoints that internally create single-node blueprints:

```http
# Execute a tool directly
POST /v1/tools/{tool_name}
{
  "inputs": { "file_path": "data.csv" },
  "wait_for_completion": true,
  "timeout": 30.0
}

# Execute an agent  
POST /v1/agents/{agent_name}
{
  "inputs": { "query": "analyze this data" }
}

# Execute a unit
POST /v1/units/{unit_name}
{
  "inputs": { "data": [...] }
}

# Execute a chain
POST /v1/chains/{chain_name}
{
  "inputs": { "context": {...} }
}

# Discovery endpoints
GET /api/v1/tools     # List all tools
GET /v1/agents        # List all agents
GET /v1/units         # List all units  
GET /v1/chains        # List all chains
```

Response includes:
- `run_id` - Track execution progress
- `status` - "completed", "running", or "failed"
- `output` - Execution results
- `telemetry_url` - Real-time event stream
- `suggestions` - AI-powered next step recommendations

### Spatial Computing Endpoints
```http
# Execute blueprint/workflow
POST /api/v1/mcp/runs
{
  "blueprint": {
    "blueprint_id": "demo_workflow",
    "nodes": [
      {
        "id": "analyze",
        "type": "llm",
        "model": "gpt-4",
        "prompt": "Analyze this: {input}",  # NOT prompt_template
        "llm_config": {
          "provider": "openai",
          "model": "gpt-4"
        }
      }
    ]
  },
  "options": {
    "max_parallel": 2,
    "retry_failed": true
  }
}

# Get graph metrics and layout hints
GET /api/v1/mcp/workflows/{workflow_id}/graph/metrics
GET /api/v1/mcp/workflows/{workflow_id}/graph/layout

# Analyze node impact for canvas updates  
GET /api/v1/mcp/workflows/{workflow_id}/nodes/{node_id}/impact

# Get Frosty AI suggestions
GET /api/v1/mcp/workflows/{workflow_id}/nodes/{node_id}/suggestions

# Find similar patterns for refactoring
POST /api/v1/mcp/workflows/{workflow_id}/graph/patterns
{
  "pattern_nodes": ["node1", "node2"]
}
```

## Architecture
```
Canvas UI ‚îÄ‚îÄ‚ñ∫ FastAPI (ice_api) ‚îÄ‚îÄ‚ñ∫ Workflow (ice_orchestrator) ‚îÄ‚îÄ‚ñ∫ ice_sdk/tools
     ‚îÇ                                   ‚îÇ
     ‚îî‚îÄ‚îÄ WebSocket ‚Üê‚îÄ‚îÄ Real-time ‚Üê‚îÄ‚îÄ Spatial Events
```
* **Spatial Intelligence**: Workflow provides NetworkX-powered graph analysis and layout hints
* **Hybrid Execution**: Direct endpoints create single-node blueprints internally, maintaining consistency while providing simple UX
* **AI Integration**: Every execution includes Frosty AI suggestions for next steps
* **Real-time Collaboration**: WebSocket gateway streams canvas updates, cursor positions, and execution events
* **Frosty Integration**: AI suggestions flow through the API for contextual canvas assistance
* Dependencies injected via `ice_api.dependencies` with spatial computing support

## Rules
* No direct DB or vectorstore access ‚Äì delegate to Tool implementations.
* All external side-effects live in `ice_sdk.tools.*`.

## Testing
`pytest tests/api` runs contract & smoke tests.

## License
MIT. 