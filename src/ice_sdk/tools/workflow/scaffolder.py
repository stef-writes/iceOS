from __future__ import annotations

import asyncio
from pathlib import Path
from typing import Optional

from pydantic import BaseModel

from ice_core.models.model_registry import get_default_model_id
from ice_core.utils.security import sanitize_path
from ice_sdk.events.dispatcher import publish
from ice_sdk.exceptions import ScaffoldValidationError
from ice_sdk.tools.base import BaseTool


class _ResourceCreatedPayload(BaseModel):
    resource_type: str
    file_path: str
    test_path: Optional[str] | None = None
    session_id: Optional[str] | None = None


class ScaffolderInput(BaseModel):
    resource_type: str  # 'chain', 'tool', 'node'
    name: str
    description: str = ""
    directory: str = "."
    force: bool = False
    validate: bool = True
    generate_test: bool = True


class ScaffolderOutput(BaseModel):
    file_path: str
    content: str
    test_path: Optional[str] = None


class WorkflowScaffolder(BaseTool):
    name = "workflow_scaffolder"
    description = "Generates workflow, tool, or node boilerplate."
    parameters_schema = ScaffolderInput.schema()
    output_schema = ScaffolderOutput.schema()

    async def run(
        self,
        ctx,
        resource_type: str,
        name: str,
        description: str = "",
        directory: str = ".",
        *,
        force: bool = False,
        validate: bool = True,
        generate_test: bool = True,
    ) -> dict:
        # Sanitize directory path to prevent path traversal
        dir_path = sanitize_path(directory)

        # Determine target path and content based on resource_type
        if resource_type == "chain":
            target_path = dir_path / f"{name}.chain.py"
            content = (
                f'"""Example ScriptChain generated by workflow scaffolder."""\n\n'
                "from ice_orchestrator import ScriptChain\n\n"
                f"class {name.capitalize()}Chain(ScriptChain):\n"
                f'    """{description or "Describe what the chain does."}"""\n    pass\n'
            )
        elif resource_type == "tool":
            target_path = dir_path / f"{name}.tool.py"
            content = (
                "from ice_sdk.tools.base import BaseTool\n\n"
                f"class {name}(BaseTool):\n"
                f'    name = "{name.lower()}"\n'
                f'    description = "{description or "Describe what the tool does."}"\n\n'
                "    async def run(self, ctx, **kwargs):\n"
                "        return {}\n"
            )
        elif resource_type == "node":
            target_path = dir_path / f"{name}.ainode.yaml"
            content = (
                f"id: {name}_ai\n"
                "type: ai\n"
                f"name: {name}\n"
                f"model: {get_default_model_id()}\n"
                "prompt: |\n  # TODO: write prompt here\n"
                "llm_config:\n  provider: openai\n  temperature: 0.7\n  max_tokens: 256\n"
                "dependencies: []\n"
            )
        else:
            raise ValueError(f"Unknown resource type: {resource_type}")

        # Idempotency check – *idempotent* scaffolds return existing file ----
        if target_path.exists() and not force:
            # Read existing content instead of raising – keeps the tool idempotent
            existing_content = target_path.read_text()
            return {
                "file_path": str(target_path),
                "content": existing_content,
                "test_path": None,
            }

        # Optionally validate content against schemas (stub) --------------
        if validate and resource_type in {"chain", "node", "tool"}:
            # TODO: Integrate real JSON schema validation – placeholder passes
            validation_ok = True
            if not validation_ok:
                raise ScaffoldValidationError(details={"path": str(target_path)})

        # Write file asynchronously --------------------------------------
        target_path.parent.mkdir(parents=True, exist_ok=True)
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, target_path.write_text, content)

        # Optionally generate test stub ----------------------------------
        test_path: str | None = None
        if generate_test:
            test_path_obj = await self._generate_test_stub(
                resource_type, name, dir_path
            )
            test_path = str(test_path_obj)

        # Emit event ------------------------------------------------------
        payload = _ResourceCreatedPayload(
            resource_type=resource_type,
            file_path=str(target_path),
            test_path=test_path,
            session_id=getattr(ctx, "session_id", None) if ctx else None,
        )
        await publish("tool.workflowScaffolder.resourceCreated", payload)

        return {
            "file_path": str(target_path),
            "content": content,
            "test_path": test_path,
        }

    @classmethod
    def validate(cls, input_data: dict) -> bool:
        # Use Pydantic validation
        try:
            ScaffolderInput(**input_data)
            return True
        except Exception:
            return False

    # ------------------------------------------------------------------
    # Internals ---------------------------------------------------------
    # ------------------------------------------------------------------

    async def _generate_test_stub(
        self, resource_type: str, name: str, base_dir: Path
    ) -> Path:
        """Generate a minimal pytest stub next to *base_dir* under tests/.*"""

        # Place test under tests/<resource_type>/ by convention ----------
        test_dir = Path.cwd() / "tests" / resource_type
        test_dir.mkdir(parents=True, exist_ok=True)

        safe_name = name.lower()
        test_filename = f"test_{safe_name}_{resource_type}.py"
        test_path = test_dir / test_filename

        stub = (
            "import pytest\n\n"
            f"@pytest.mark.asyncio\nasync def test_{safe_name}():\n"
            "    assert True  # Auto-generated stub – replace with real tests\n"
        )

        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, test_path.write_text, stub)

        return test_path
