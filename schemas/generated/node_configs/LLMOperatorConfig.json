{
  "$defs": {
    "ContextFormat": {
      "enum": [
        "text",
        "json",
        "markdown",
        "code",
        "custom"
      ],
      "title": "ContextFormat",
      "type": "string"
    },
    "ContextRule": {
      "description": "Rule for handling context in a node.",
      "properties": {
        "include": {
          "default": true,
          "description": "Whether to include this context",
          "title": "Include",
          "type": "boolean"
        },
        "format": {
          "$ref": "#/$defs/ContextFormat",
          "default": "text",
          "description": "Format of the context"
        },
        "required": {
          "default": false,
          "description": "Whether this context is required",
          "title": "Required",
          "type": "boolean"
        },
        "max_tokens": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Maximum tokens allowed for this context",
          "title": "Max Tokens"
        },
        "truncate": {
          "default": true,
          "description": "Whether to truncate if context exceeds max_tokens",
          "title": "Truncate",
          "type": "boolean"
        }
      },
      "title": "ContextRule",
      "type": "object"
    },
    "InputMapping": {
      "description": "Mapping configuration for node inputs.",
      "properties": {
        "source_node_id": {
          "description": "Source node ID (UUID of the dependency)",
          "title": "Source Node Id",
          "type": "string"
        },
        "source_output_key": {
          "description": "Key from the source node's output object to use (e.g. 'text', 'result', 'data.items.0')",
          "title": "Source Output Key",
          "type": "string"
        },
        "rules": {
          "additionalProperties": true,
          "description": "Optional transformation rules (e.g. 'truncate', 'format')",
          "title": "Rules",
          "type": "object"
        }
      },
      "required": [
        "source_node_id",
        "source_output_key"
      ],
      "title": "InputMapping",
      "type": "object"
    },
    "LLMConfig": {
      "additionalProperties": true,
      "description": "Provider-specific configuration for LLM calls.",
      "properties": {
        "provider": {
          "$ref": "#/$defs/ModelProvider",
          "default": "openai"
        },
        "model": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Model"
        },
        "temperature": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Temperature"
        },
        "max_tokens": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Max Tokens"
        },
        "max_context_tokens": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Max Context Tokens"
        },
        "api_key": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Api Key"
        },
        "base_url": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Base Url"
        },
        "timeout": {
          "default": 30,
          "title": "Timeout",
          "type": "integer"
        },
        "max_retries": {
          "default": 3,
          "title": "Max Retries",
          "type": "integer"
        },
        "top_p": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Top P"
        },
        "frequency_penalty": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Frequency Penalty"
        },
        "presence_penalty": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Presence Penalty"
        },
        "stop_sequences": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Stop Sequences"
        },
        "openai_api_version": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Openai Api Version"
        },
        "anthropic_version": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Anthropic Version"
        },
        "custom_parameters": {
          "additionalProperties": true,
          "description": "Provider-specific parameters",
          "title": "Custom Parameters",
          "type": "object"
        }
      },
      "title": "LLMConfig",
      "type": "object"
    },
    "ModelProvider": {
      "description": "Supported LLM providers.",
      "enum": [
        "openai",
        "anthropic",
        "google",
        "deepseek",
        "custom"
      ],
      "title": "ModelProvider",
      "type": "string"
    },
    "NodeMetadata": {
      "description": "Metadata model for node versioning and ownership.\n\nThis is a near verbatim copy of the former *ice_sdk.models.node_models.NodeMetadata*\nto kick-off the migration.  Once downstream code switches to this definition\nthe legacy one will be deprecated and removed.",
      "properties": {
        "node_id": {
          "description": "Unique node identifier",
          "title": "Node Id",
          "type": "string"
        },
        "node_type": {
          "description": "Type of node (tool, llm, agent, etc.)",
          "title": "Node Type",
          "type": "string"
        },
        "name": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Name"
        },
        "version": {
          "default": "1.0.0",
          "description": "Semantic version of node configuration",
          "pattern": "^\\d+\\.\\d+\\.\\d+$",
          "title": "Version",
          "type": "string"
        },
        "owner": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Node owner/maintainer",
          "title": "Owner"
        },
        "created_at": {
          "anyOf": [
            {
              "format": "date-time",
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Created At"
        },
        "modified_at": {
          "anyOf": [
            {
              "format": "date-time",
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Modified At"
        },
        "description": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Description of the node",
          "title": "Description"
        },
        "error_type": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Type of error if execution failed",
          "title": "Error Type"
        },
        "timestamp": {
          "anyOf": [
            {
              "format": "date-time",
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Timestamp"
        },
        "start_time": {
          "anyOf": [
            {
              "format": "date-time",
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Execution start time",
          "title": "Start Time"
        },
        "end_time": {
          "anyOf": [
            {
              "format": "date-time",
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Execution end time",
          "title": "End Time"
        },
        "duration": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Execution duration in seconds",
          "title": "Duration"
        },
        "tags": {
          "description": "Categorisation tags for the node (e.g. 'safety', 'experimental')",
          "items": {
            "type": "string"
          },
          "title": "Tags",
          "type": "array"
        },
        "provider": {
          "anyOf": [
            {
              "$ref": "#/$defs/ModelProvider"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "LLM provider used for execution"
        },
        "retry_count": {
          "default": 0,
          "description": "Number of retry attempts performed during node execution",
          "minimum": 0,
          "title": "Retry Count",
          "type": "integer"
        }
      },
      "required": [
        "node_id",
        "node_type"
      ],
      "title": "NodeMetadata",
      "type": "object"
    },
    "RetryPolicy": {
      "description": "Declarative retry policy attached to any node.\n\nAttributes\n----------\nmax_attempts : int\n    Maximum number of attempts (including the first one).  Value **must** be\n    ≥ 1.\nbackoff_strategy : Literal[\"fixed\", \"linear\", \"exponential\"]\n    Algorithm used to calculate the wait time before the next retry.\nbackoff_seconds : float\n    Base seconds used by the strategy.  For *fixed* the wait time is\n    exactly *backoff_seconds*, for *linear* it is `backoff_seconds * n`, and\n    for *exponential* it is `backoff_seconds * 2**n` where *n* is the\n    current attempt index (starting at 0).",
      "properties": {
        "max_attempts": {
          "default": 3,
          "minimum": 1,
          "title": "Max Attempts",
          "type": "integer"
        },
        "backoff_strategy": {
          "default": "exponential",
          "enum": [
            "fixed",
            "linear",
            "exponential"
          ],
          "title": "Backoff Strategy",
          "type": "string"
        },
        "backoff_seconds": {
          "default": 1.0,
          "minimum": 0.0,
          "title": "Backoff Seconds",
          "type": "number"
        }
      },
      "title": "RetryPolicy",
      "type": "object"
    }
  },
  "additionalProperties": false,
  "description": "LLM operator configuration - Pure text generation without tools.\n\nWHY: For stateless, one-shot LLM operations. NO tool access.\nIf you need tools, use AgentNodeConfig instead.\n\nUse this for: Summarization, extraction, translation, single Q&A\nUse AgentNodeConfig for: Any LLM operation that needs tools or memory\n\nIn Frosty: \"summarize in 3 bullets\" → LLMOperatorConfig with template",
  "properties": {
    "id": {
      "description": "Unique identifier for the node",
      "title": "Id",
      "type": "string"
    },
    "type": {
      "const": "llm",
      "default": "llm",
      "title": "Type",
      "type": "string"
    },
    "name": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Human-readable name",
      "title": "Name"
    },
    "dependencies": {
      "description": "IDs of prerequisite nodes",
      "items": {
        "type": "string"
      },
      "title": "Dependencies",
      "type": "array"
    },
    "level": {
      "default": 0,
      "description": "Execution level for parallelism",
      "title": "Level",
      "type": "integer"
    },
    "metadata": {
      "anyOf": [
        {
          "$ref": "#/$defs/NodeMetadata"
        },
        {
          "type": "null"
        }
      ],
      "default": null
    },
    "provider": {
      "$ref": "#/$defs/ModelProvider",
      "default": "openai",
      "description": "Model provider for the node"
    },
    "timeout_seconds": {
      "anyOf": [
        {
          "minimum": 1,
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Hard timeout for node execution in seconds (None = no timeout)",
      "title": "Timeout Seconds"
    },
    "retries": {
      "default": 0,
      "description": "Maximum number of retries if the node execution fails",
      "minimum": 0,
      "title": "Retries",
      "type": "integer"
    },
    "backoff_seconds": {
      "default": 0.0,
      "description": "Base backoff seconds for exponential retry backoff (0 disables)",
      "minimum": 0.0,
      "title": "Backoff Seconds",
      "type": "number"
    },
    "retry_policy": {
      "anyOf": [
        {
          "$ref": "#/$defs/RetryPolicy"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Structured retry policy (overrides 'retries' & 'backoff_seconds' when provided)"
    },
    "input_schema": {
      "anyOf": [
        {
          "additionalProperties": true,
          "type": "object"
        },
        {}
      ],
      "title": "Input Schema"
    },
    "output_schema": {
      "anyOf": [
        {
          "additionalProperties": true,
          "type": "object"
        },
        {}
      ],
      "title": "Output Schema"
    },
    "input_mappings": {
      "additionalProperties": {
        "$ref": "#/$defs/InputMapping"
      },
      "title": "Input Mappings",
      "type": "object"
    },
    "output_mappings": {
      "additionalProperties": {
        "type": "string"
      },
      "title": "Output Mappings",
      "type": "object"
    },
    "use_cache": {
      "default": true,
      "description": "Whether the orchestrator should reuse cached results when the context & config are unchanged.",
      "title": "Use Cache",
      "type": "boolean"
    },
    "input_selection": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "List of input keys to include (None = all)",
      "title": "Input Selection"
    },
    "output_selection": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "List of output keys to include (None = all)",
      "title": "Output Selection"
    },
    "context_rules": {
      "additionalProperties": {
        "$ref": "#/$defs/ContextRule"
      },
      "title": "Context Rules",
      "type": "object"
    },
    "model": {
      "description": "Model name, e.g. gpt-3.5-turbo",
      "title": "Model",
      "type": "string"
    },
    "prompt": {
      "description": "Prompt template",
      "title": "Prompt",
      "type": "string"
    },
    "llm_config": {
      "$ref": "#/$defs/LLMConfig",
      "description": "Provider-specific parameters"
    },
    "temperature": {
      "default": 0.7,
      "title": "Temperature",
      "type": "number"
    },
    "max_tokens": {
      "anyOf": [
        {
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "title": "Max Tokens"
    },
    "format_specifications": {
      "additionalProperties": true,
      "title": "Format Specifications",
      "type": "object"
    },
    "coerce_output_types": {
      "default": true,
      "title": "Coerce Output Types",
      "type": "boolean"
    },
    "coerce_input_types": {
      "default": true,
      "title": "Coerce Input Types",
      "type": "boolean"
    },
    "output_format": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Expected output format",
      "title": "Output Format"
    },
    "json_schema": {
      "anyOf": [
        {
          "additionalProperties": true,
          "type": "object"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "JSON schema for output",
      "title": "Json Schema"
    }
  },
  "required": [
    "id",
    "model",
    "prompt",
    "llm_config"
  ],
  "title": "LLMOperatorConfig",
  "type": "object",
  "$id": "https://iceos.ai/schemas/LLMOperatorConfig.json",
  "$comment": "Generated from ice_core.models.node_models.LLMOperatorConfig",
  "x-iceos-version": "1.0.0"
}
